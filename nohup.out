
Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:7869
  Network URL: http://172.31.11.95:7869
  External URL: http://44.229.65.238:7869

2025-08-06 00:28:53,322 - 140307154163456 - user_agent.py-user_agent:11 - WARNING: USER_AGENT environment variable not set, consider setting it to identify your requests.
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:36: LangChainDeprecationWarning: Importing WebResearchRetriever from langchain.retrievers is deprecated. Please replace deprecated imports:

>> from langchain.retrievers import WebResearchRetriever

with new imports of:

>> from langchain_community.retrievers.web_research import WebResearchRetriever
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.retrievers.web_research import WebResearchRetriever
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:39: LangChainDeprecationWarning: Importing load_tools from langchain.agents is deprecated. Please replace deprecated imports:

>> from langchain.agents import load_tools

with new imports of:

>> from langchain_community.agent_toolkits.load_tools import load_tools
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.agents import AgentExecutor, create_react_agent, initialize_agent, AgentType,load_tools
2025-08-06 00:28:54.053 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/cavatar-dev/demo/mmrag/home.py", line 35, in <module>
    from utils import *
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py", line 41, in <module>
    from serpapi import GoogleSearch #, BingSearch
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'GoogleSearch' from 'serpapi' (/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/serpapi/__init__.py)
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:36: LangChainDeprecationWarning: Importing WebResearchRetriever from langchain.retrievers is deprecated. Please replace deprecated imports:

>> from langchain.retrievers import WebResearchRetriever

with new imports of:

>> from langchain_community.retrievers.web_research import WebResearchRetriever
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.retrievers.web_research import WebResearchRetriever
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:39: LangChainDeprecationWarning: Importing load_tools from langchain.agents is deprecated. Please replace deprecated imports:

>> from langchain.agents import load_tools

with new imports of:

>> from langchain_community.agent_toolkits.load_tools import load_tools
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.agents import AgentExecutor, create_react_agent, initialize_agent, AgentType,load_tools
2025-08-06 00:29:29.329 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/cavatar-dev/demo/mmrag/home.py", line 35, in <module>
    from utils import *
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py", line 41, in <module>
    from serpapi import GoogleSearch #, BingSearch
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'GoogleSearch' from 'serpapi' (/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/serpapi/__init__.py)
  Stopping...

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:7869
  Network URL: http://172.31.11.95:7869
  External URL: http://44.229.65.238:7869

USER_AGENT environment variable not set, consider setting it to identify your requests.
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:36: LangChainDeprecationWarning: Importing WebResearchRetriever from langchain.retrievers is deprecated. Please replace deprecated imports:

>> from langchain.retrievers import WebResearchRetriever

with new imports of:

>> from langchain_community.retrievers.web_research import WebResearchRetriever
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.retrievers.web_research import WebResearchRetriever
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:39: LangChainDeprecationWarning: Importing load_tools from langchain.agents is deprecated. Please replace deprecated imports:

>> from langchain.agents import load_tools

with new imports of:

>> from langchain_community.agent_toolkits.load_tools import load_tools
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.agents import AgentExecutor, create_react_agent, initialize_agent, AgentType,load_tools
2025-08-06 00:29:47.985 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 14, in <module>
    from configs.utils import *
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py", line 41, in <module>
    from serpapi import GoogleSearch #, BingSearch
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError: cannot import name 'GoogleSearch' from 'serpapi' (/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/serpapi/__init__.py)
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:36: LangChainDeprecationWarning: Importing WebResearchRetriever from langchain.retrievers is deprecated. Please replace deprecated imports:

>> from langchain.retrievers import WebResearchRetriever

with new imports of:

>> from langchain_community.retrievers.web_research import WebResearchRetriever
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.retrievers.web_research import WebResearchRetriever
/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py:39: LangChainDeprecationWarning: Importing load_tools from langchain.agents is deprecated. Please replace deprecated imports:

>> from langchain.agents import load_tools

with new imports of:

>> from langchain_community.agent_toolkits.load_tools import load_tools
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.agents import AgentExecutor, create_react_agent, initialize_agent, AgentType,load_tools
2025-08-06 00:30:16.796 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 14, in <module>
    from configs.utils import *
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utils.py", line 42, in <module>
    from langchain_deepseek import ChatDeepSeek
ModuleNotFoundError: No module named 'langchain_deepseek'
2025-08-06 00:34:27.320 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 31, in <module>
    aoss_host = read_key_value(".aoss_config.txt", "AOSS_host_name")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 366, in read_key_value
    with open(file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '.aoss_config.txt'
2025-08-06 00:35:13.029 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 193, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'object': 'error', 'message': 'The model `gemma-3N-finetune` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}
2025-08-06 00:36:21.938 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 205, in <module>
    usages = f'Completion_tokens: {response.usage.completion_tokens}, Prompt_tokens: {response.usage.prompt_tokens}, Total_tokens:{response.usage.total_tokens}'
                                   ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'usage'
2025-08-06 00:43:41.859 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 195, in <module>
    file_bytes = b64encode(file.read()).decode('utf-8')
                 ^^^^^^^^^
NameError: name 'b64encode' is not defined
2025-08-06 00:43:58.354 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 201, in <module>
    file_contents = {"url": f"data:image/jpeg;base64,{encoded_bytes}"}
                                                      ^^^^^^^^^^^^^
NameError: name 'encoded_bytes' is not defined
2025-08-06 00:44:17.962 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 214, in <module>
    message_content.append({"type": "text", "text": query})
                                                    ^^^^^
NameError: name 'query' is not defined
2025-08-06 00:44:31.762 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 221, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'alfredcs/gemma-3N-finetune is not a multimodal model None', 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 00:52:36.248 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 224, in <module>
    response = convert_to_markdown(local_gemma3n_image(message_content, max_token))
                                   ^^^^^^^^^^^^^^^^^^^
NameError: name 'local_gemma3n_image' is not defined
2025-08-06 00:52:57.174 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 224, in <module>
    response = convert_to_markdown(local_gemma3n_image(message_content, max_token))
                                                                        ^^^^^^^^^
NameError: name 'max_token' is not defined
2025-08-06 00:53:28.136 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 224, in <module>
    response = convert_to_markdown(local_gemma3n_image(message_content, max_tokens))
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 965, in local_gemma3n_image
    client = OpenAI(
             ^^^^^^
NameError: name 'OpenAI' is not defined
2025-08-06 00:53:54.358 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/pydantic/main.py", line 848, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'split'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 224, in <module>
    response = convert_to_markdown(local_gemma3n_image(message_content, max_tokens))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 943, in convert_to_markdown
    lines = text.split('\n')
            ^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/pydantic/main.py", line 850, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletion' object has no attribute 'split'
2025-08-06 00:58:34.705 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 228, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'alfredcs/gemma-3N-finetune is not a multimodal model None', 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 00:59:38.621 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 226, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'user', 'content...ext': 'what is this?'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:00:23.662 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 228, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'Conversation roles must alternate user/assistant/user/assistant/... Conversation roles must alternate user/assistant/user/assistant/...', 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:00:44.430 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 228, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'Conversation roles must alternate user/assistant/user/assistant/... Conversation roles must alternate user/assistant/user/assistant/...', 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:00:51.414 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 228, in <module>
    response = st.session_state["openai_client"].chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': 'Conversation roles must alternate user/assistant/user/assistant/... Conversation roles must alternate user/assistant/user/assistant/...', 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:01:16.975 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 222, in <module>
    st.chat_message("user").write(messages)
                                  ^^^^^^^^
NameError: name 'messages' is not defined
2025-08-06 01:01:29.776 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 226, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:02:00.700 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 227, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:03:43.204 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 226, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:05:51.482 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 227, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
2025-08-06 01:06:35.864 Uncaught app exception
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/exec_code.py", line 88, in exec_func_with_error_handling
    result = func()
             ^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py", line 579, in code_to_exec
    exec(code, module.__dict__)
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/home.py", line 231, in <module>
    response = local_gemma3n_image(st.session_state.messages, max_tokens)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/configs/utility.py", line 971, in local_gemma3n_image
    chat_response = client.chat.completions.create(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 815, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_base_client.py", line 1058, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': "8 validation errors for ValidatorIterator\n0.ChatCompletionContentPartTextParam.text\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartTextParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.image_url\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartImageParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.input_audio\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.ChatCompletionContentPartInputAudioParam.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.file\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n0.File.type\n  Field required [type=missing, input_value={'role': 'system', 'conte...rately and truthfully.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing None", 'type': 'BadRequestError', 'param': None, 'code': 400}
  Stopping...

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:7869
  Network URL: http://172.31.11.95:7869
  External URL: http://44.229.65.238:7869

  Stopping...

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:7868
  Network URL: http://172.31.11.95:7868
  External URL: http://44.229.65.238:7868

[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m187[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m184 [0m                                                                               [31m [0m
[31m [0m   [2m185 [0m[94mif[0m prompt := st.chat_input():                                                  [31m [0m
[31m [0m   [2m186 [0m[2m│   [0m[2m# Override query with voice prompt[0m                                         [31m [0m
[31m [0m [31m❱ [0m187 [2m│   [0m[2m# if len([0m[1;2;4mvoice_prompt) > 3[0m[2m:[0m                                                [31m [0m
[31m [0m   [2m188 [0m[2m│   [0m[2m#     prompt = voice_prompt[0m                                                [31m [0m
[31m [0m   [2m189 [0m[2m│   [0m                                                                           [31m [0m
[31m [0m   [2m190 [0m[2m│   [0m[2m# Add relevant files to message content[0m                                    [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mTypeError: [0munsupported operand [1;35mtype[0m[1m([0ms[1m)[0m for +: [32m'bool'[0m and [32m'str'[0m
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m187[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m184 [0m                                                                               [31m [0m
[31m [0m   [2m185 [0m[94mif[0m prompt := st.chat_input() [95mor[0m [96mlen[0m(voice_prompt) > [94m3[0m:                         [31m [0m
[31m [0m   [2m186 [0m[2m│   [0mprompt_flag = prompt [95mis[0m [96mstr[0m                                                [31m [0m
[31m [0m [31m❱ [0m187 [2m│   [0mst.write([1;4mprompt_flag + [0m[1;4;33m"[0m[1;4;33m|[0m[1;4;33m"[0m[1;4m + prompt)[0m                                       [31m [0m
[31m [0m   [2m188 [0m[2m│   [0m[2m# Override query with voice prompt[0m                                         [31m [0m
[31m [0m   [2m189 [0m[2m│   [0m[94mif[0m [96mlen[0m(voice_prompt) > [94m3[0m:                                                  [31m [0m
[31m [0m   [2m190 [0m[2m│   │   [0mprompt = voice_prompt                                                  [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mTypeError: [0mcan only concatenate str [1m([0mnot [32m"type"[0m[1m)[0m to str
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m187[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m184 [0m                                                                               [31m [0m
[31m [0m   [2m185 [0m[94mif[0m prompt := st.chat_input() [95mor[0m [96mlen[0m(voice_prompt) > [94m3[0m:                         [31m [0m
[31m [0m   [2m186 [0m[2m│   [0mprompt_flag = prompt [95mis[0m [96mstr[0m                                                [31m [0m
[31m [0m [31m❱ [0m187 [2m│   [0mst.write([1;4;96mstr[0m[1;4m(prompt_flag) + [0m[1;4;33m"[0m[1;4;33m|[0m[1;4;33m"[0m[1;4m + prompt[0m + [33m"[0m[33m|[0m[33m"[0m + [96mtype[0m(prompt))             [31m [0m
[31m [0m   [2m188 [0m[2m│   [0m[2m# Override query with voice prompt[0m                                         [31m [0m
[31m [0m   [2m189 [0m[2m│   [0m[94mif[0m [96mlen[0m(voice_prompt) > [94m3[0m:                                                  [31m [0m
[31m [0m   [2m190 [0m[2m│   │   [0mprompt = voice_prompt                                                  [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mTypeError: [0mcan only concatenate str [1m([0mnot [32m"bool"[0m[1m)[0m to str

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.

2025-08-06 01:54:13.970 Port 7868 is already in use
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m161[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m158 [0m[2m│   │   │   [0mst.session_state.messages.clear()                                  [31m [0m
[31m [0m   [2m159 [0m[2m│   │   │   [0mst.session_state[[33m"[0m[33mmessages[0m[33m"[0m] = [                                   [31m [0m
[31m [0m   [2m160 [0m[2m│   │   │   │   [0m{[33m"[0m[33mrole[0m[33m"[0m: [33m"[0m[33massistant[0m[33m"[0m, [33m"[0m[33mcontent[0m[33m"[0m: [33m"[0m[33mI am your assistant. How can[0m [31m [0m
[31m [0m [31m❱ [0m161 [2m│   │   │   [0mr[1;4mecor[0md_audio = [94mNone[0m                                                [31m [0m
[31m [0m   [2m162 [0m[2m│   │   │   [0mvoice_prompt = [33m"[0m[33m"[0m                                                  [31m [0m
[31m [0m   [2m163 [0m                                                                               [31m [0m
[31m [0m   [2m164 [0m[2m# ----------------------------------------------------------------------------[0m [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mNameError: [0mname [32m'time'[0m is not defined
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m228[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m225 [0m[2m│   │   │   [0mmessages=st.session_state.messages_no_files,                       [31m [0m
[31m [0m   [2m226 [0m[2m│   │   │   [0mstream=[94mFalse[0m,                                                      [31m [0m
[31m [0m   [2m227 [0m[2m│   │   │   [0mtemperature=temperature,                                           [31m [0m
[31m [0m [31m❱ [0m228 [2m│   │   │   [0mmax_tok[1;4mens=max_tokens,[0m                                             [31m [0m
[31m [0m   [2m229 [0m[2m│   │   │   [0mtop_p=top_p                                                        [31m [0m
[31m [0m   [2m230 [0m[2m│   │   [0m)                                                                      [31m [0m
[31m [0m   [2m231 [0m[2m│   [0mfooter = [33mf[0m[33m'[0m[33mCompletion Tokens: [0m[33m{[0mresponse.usage.completion_tokens[33m}[0m[33m, Prompt T[0m [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mutility.py[0m:[94m68[0m in            [31m [0m
[31m [0m [92mlocal_gemma3n_image[0m                                                                  [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m65 [0m[2m│   │   [0mbase_url=openai_api_base,                                               [31m [0m
[31m [0m   [2m66 [0m[2m│   [0m)                                                                           [31m [0m
[31m [0m   [2m67 [0m[2m│   [0m                                                                            [31m [0m
[31m [0m [31m❱ [0m68 [2m│   [0mchat_response = client.chat.completions.create(                             [31m [0m
[31m [0m   [2m69 [0m[2m│   │   [0mmodel=model_id,                                                         [31m [0m
[31m [0m   [2m70 [0m[2m│   │   [0mmessages=[                                                              [31m [0m
[31m [0m   [2m71 [0m[2m│   │   │   [0m{[33m"[0m[33mrole[0m[33m"[0m: [33m"[0m[33msystem[0m[33m"[0m, [33m"[0m[33mcontent[0m[33m"[0m: [33m"[0m[33mYou are a helpful assistant. Please [0m [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/[0m[1;33m_utils.py[0m [31m [0m
[31m [0m :[94m274[0m in [92mwrapper[0m                                                                      [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m271 [0m[2m│   │   │   │   │   [0m[94melse[0m:                                                      [31m [0m
[31m [0m   [2m272 [0m[2m│   │   │   │   │   │   [0mmsg = [33mf[0m[33m"[0m[33mMissing required argument: [0m[33m{[0mquote(missing[[94m0[0m])[33m}[0m [31m [0m
[31m [0m   [2m273 [0m[2m│   │   │   │   [0m[94mraise[0m [96mTypeError[0m(msg)                                           [31m [0m
[31m [0m [31m❱ [0m274 [2m│   │   │   [0m[94mreturn[0m [1;4mfunc(*args, **kwargs)[0m                                       [31m [0m
[31m [0m   [2m275 [0m[2m│   │   [0m                                                                       [31m [0m
[31m [0m   [2m276 [0m[2m│   │   [0m[94mreturn[0m wrapper  [2m# type: ignore[0m                                         [31m [0m
[31m [0m   [2m277 [0m                                                                               [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/[0m[1;33mc[0m [31m [0m
[31m [0m [1;33mompletions.py[0m:[94m815[0m in [92mcreate[0m                                                          [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 812 [0m[2m│   │   [0mtimeout: [96mfloat[0m | httpx.Timeout | [94mNone[0m | NotGiven = NOT_GIVEN,         [31m [0m
[31m [0m   [2m 813 [0m[2m│   [0m) -> ChatCompletion | Stream[ChatCompletionChunk]:                        [31m [0m
[31m [0m   [2m 814 [0m[2m│   │   [0mvalidate_response_format(response_format)                             [31m [0m
[31m [0m [31m❱ [0m 815 [2m│   │   [0m[94mreturn[0m [96mself[0m._post(                                                    [31m [0m
[31m [0m   [2m 816 [0m[2m│   │   │   [0m[33m"[0m[33m/chat/completions[0m[33m"[0m,                                              [31m [0m
[31m [0m   [2m 817 [0m[2m│   │   │   [0mbody=maybe_transform(                                             [31m [0m
[31m [0m   [2m 818 [0m[2m│   │   │   │   [0m{                                                             [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1277[0m in [92mpost[0m                                                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1274 [0m[2m│   │   [0mopts = FinalRequestOptions.construct(                                 [31m [0m
[31m [0m   [2m1275 [0m[2m│   │   │   [0mmethod=[33m"[0m[33mpost[0m[33m"[0m, url=path, json_data=body, files=to_httpx_files(fil [31m [0m
[31m [0m   [2m1276 [0m[2m│   │   [0m)                                                                     [31m [0m
[31m [0m [31m❱ [0m1277 [2m│   │   [0m[94mreturn[0m cast(ResponseT, [1;4;96mself[0m[1;4m.request(cast_to, opts, stream=stream, str[0m [31m [0m
[31m [0m   [2m1278 [0m[2m│   [0m                                                                          [31m [0m
[31m [0m   [2m1279 [0m[2m│   [0m[94mdef[0m [92mpatch[0m(                                                                [31m [0m
[31m [0m   [2m1280 [0m[2m│   │   [0m[96mself[0m,                                                                 [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m954[0m in [92mrequest[0m                                                                       [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 951 [0m[2m│   │   [0m[94melse[0m:                                                                 [31m [0m
[31m [0m   [2m 952 [0m[2m│   │   │   [0mretries_taken = [94m0[0m                                                 [31m [0m
[31m [0m   [2m 953 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m [31m❱ [0m 954 [2m│   │   [0m[94mreturn[0m [96mself[0m._request(                                                 [31m [0m
[31m [0m   [2m 955 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m [0m   [2m 956 [0m[2m│   │   │   [0moptions=options,                                                  [31m [0m
[31m [0m   [2m 957 [0m[2m│   │   │   [0mstream=stream,                                                    [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1058[0m in [92m_request[0m                                                                     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1055 [0m[2m│   │   │   │   [0merr.response.read()                                           [31m [0m
[31m [0m   [2m1056 [0m[2m│   │   │   [0m                                                                  [31m [0m
[31m [0m   [2m1057 [0m[2m│   │   │   [0mlog.debug([33m"[0m[33mRe-raising status error[0m[33m"[0m)                              [31m [0m
[31m [0m [31m❱ [0m1058 [2m│   │   │   [0m[1;4;94mraise[0m[1;4m [0m[1;4;96mself[0m[1;4m._make_status_error_from_response(err.response) [0m[1;4;94mfrom[0m[1;4m [0m[1;4;94mNo[0m [31m [0m
[31m [0m   [2m1059 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m   [2m1060 [0m[2m│   │   [0m[94mreturn[0m [96mself[0m._process_response(                                        [31m [0m
[31m [0m   [2m1061 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mBadRequestError: [0mError code: [1;36m400[0m - [1m{[0m[32m'object'[0m: [32m'error'[0m, [32m'message'[0m: [32m'At most 0 audio[0m[32m([0m[32ms[0m[32m)[0m[32m [0m
[32mmay be provided in one request. You can set `--limit-mm-per-prompt` to increase this [0m
[32mlimit if the model supports it. None'[0m, [32m'type'[0m: [32m'BadRequestError'[0m, [32m'param'[0m: [3;35mNone[0m, [32m'code'[0m:
[1;36m400[0m[1m}[0m
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m228[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m225 [0m[2m│   [0m                                                                           [31m [0m
[31m [0m   [2m226 [0m[2m│   [0m[2m# Generate response[0m                                                        [31m [0m
[31m [0m   [2m227 [0m[2m│   [0m[94mif[0m with_files:                                                             [31m [0m
[31m [0m [31m❱ [0m228 [2m│   │   [0mresponse = [1;4mlocal_gemma3n_image(message_content, max_tokens)[0m            [31m [0m
[31m [0m   [2m229 [0m[2m│   [0m[94melse[0m:                                                                      [31m [0m
[31m [0m   [2m230 [0m[2m│   │   [0mresponse = st.session_state[[33m"[0m[33mopenai_client[0m[33m"[0m].chat.completions.create(  [31m [0m
[31m [0m   [2m231 [0m[2m│   │   │   [0mmodel=model_id,                                                    [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mutility.py[0m:[94m68[0m in            [31m [0m
[31m [0m [92mlocal_gemma3n_image[0m                                                                  [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m65 [0m[2m│   │   [0mbase_url=openai_api_base,                                               [31m [0m
[31m [0m   [2m66 [0m[2m│   [0m)                                                                           [31m [0m
[31m [0m   [2m67 [0m[2m│   [0m                                                                            [31m [0m
[31m [0m [31m❱ [0m68 [2m│   [0mchat_response = client.chat.completions.create(                             [31m [0m
[31m [0m   [2m69 [0m[2m│   │   [0mmodel=model_id,                                                         [31m [0m
[31m [0m   [2m70 [0m[2m│   │   [0mmessages=[                                                              [31m [0m
[31m [0m   [2m71 [0m[2m│   │   │   [0m{[33m"[0m[33mrole[0m[33m"[0m: [33m"[0m[33msystem[0m[33m"[0m, [33m"[0m[33mcontent[0m[33m"[0m: [33m"[0m[33mYou are a helpful assistant. Please [0m [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/[0m[1;33m_utils.py[0m [31m [0m
[31m [0m :[94m274[0m in [92mwrapper[0m                                                                      [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m271 [0m[2m│   │   │   │   │   [0m[94melse[0m:                                                      [31m [0m
[31m [0m   [2m272 [0m[2m│   │   │   │   │   │   [0mmsg = [33mf[0m[33m"[0m[33mMissing required argument: [0m[33m{[0mquote(missing[[94m0[0m])[33m}[0m [31m [0m
[31m [0m   [2m273 [0m[2m│   │   │   │   [0m[94mraise[0m [96mTypeError[0m(msg)                                           [31m [0m
[31m [0m [31m❱ [0m274 [2m│   │   │   [0m[94mreturn[0m [1;4mfunc(*args, **kwargs)[0m                                       [31m [0m
[31m [0m   [2m275 [0m[2m│   │   [0m                                                                       [31m [0m
[31m [0m   [2m276 [0m[2m│   │   [0m[94mreturn[0m wrapper  [2m# type: ignore[0m                                         [31m [0m
[31m [0m   [2m277 [0m                                                                               [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/[0m[1;33mc[0m [31m [0m
[31m [0m [1;33mompletions.py[0m:[94m815[0m in [92mcreate[0m                                                          [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 812 [0m[2m│   │   [0mtimeout: [96mfloat[0m | httpx.Timeout | [94mNone[0m | NotGiven = NOT_GIVEN,         [31m [0m
[31m [0m   [2m 813 [0m[2m│   [0m) -> ChatCompletion | Stream[ChatCompletionChunk]:                        [31m [0m
[31m [0m   [2m 814 [0m[2m│   │   [0mvalidate_response_format(response_format)                             [31m [0m
[31m [0m [31m❱ [0m 815 [2m│   │   [0m[94mreturn[0m [96mself[0m._post(                                                    [31m [0m
[31m [0m   [2m 816 [0m[2m│   │   │   [0m[33m"[0m[33m/chat/completions[0m[33m"[0m,                                              [31m [0m
[31m [0m   [2m 817 [0m[2m│   │   │   [0mbody=maybe_transform(                                             [31m [0m
[31m [0m   [2m 818 [0m[2m│   │   │   │   [0m{                                                             [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1277[0m in [92mpost[0m                                                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1274 [0m[2m│   │   [0mopts = FinalRequestOptions.construct(                                 [31m [0m
[31m [0m   [2m1275 [0m[2m│   │   │   [0mmethod=[33m"[0m[33mpost[0m[33m"[0m, url=path, json_data=body, files=to_httpx_files(fil [31m [0m
[31m [0m   [2m1276 [0m[2m│   │   [0m)                                                                     [31m [0m
[31m [0m [31m❱ [0m1277 [2m│   │   [0m[94mreturn[0m cast(ResponseT, [1;4;96mself[0m[1;4m.request(cast_to, opts, stream=stream, str[0m [31m [0m
[31m [0m   [2m1278 [0m[2m│   [0m                                                                          [31m [0m
[31m [0m   [2m1279 [0m[2m│   [0m[94mdef[0m [92mpatch[0m(                                                                [31m [0m
[31m [0m   [2m1280 [0m[2m│   │   [0m[96mself[0m,                                                                 [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m954[0m in [92mrequest[0m                                                                       [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 951 [0m[2m│   │   [0m[94melse[0m:                                                                 [31m [0m
[31m [0m   [2m 952 [0m[2m│   │   │   [0mretries_taken = [94m0[0m                                                 [31m [0m
[31m [0m   [2m 953 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m [31m❱ [0m 954 [2m│   │   [0m[94mreturn[0m [96mself[0m._request(                                                 [31m [0m
[31m [0m   [2m 955 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m [0m   [2m 956 [0m[2m│   │   │   [0moptions=options,                                                  [31m [0m
[31m [0m   [2m 957 [0m[2m│   │   │   [0mstream=stream,                                                    [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1058[0m in [92m_request[0m                                                                     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1055 [0m[2m│   │   │   │   [0merr.response.read()                                           [31m [0m
[31m [0m   [2m1056 [0m[2m│   │   │   [0m                                                                  [31m [0m
[31m [0m   [2m1057 [0m[2m│   │   │   [0mlog.debug([33m"[0m[33mRe-raising status error[0m[33m"[0m)                              [31m [0m
[31m [0m [31m❱ [0m1058 [2m│   │   │   [0m[1;4;94mraise[0m[1;4m [0m[1;4;96mself[0m[1;4m._make_status_error_from_response(err.response) [0m[1;4;94mfrom[0m[1;4m [0m[1;4;94mNo[0m [31m [0m
[31m [0m   [2m1059 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m   [2m1060 [0m[2m│   │   [0m[94mreturn[0m [96mself[0m._process_response(                                        [31m [0m
[31m [0m   [2m1061 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mNotFoundError: [0mError code: [1;36m404[0m - [1m{[0m[32m'detail'[0m: [32m'Not Found'[0m[1m}[0m
[31m──[0m[31m────────────────────────[0m[31m [0m[1;31mTraceback [0m[1;2;31m(most recent call last)[0m[31m [0m[31m─────────────────────────[0m[31m──[0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mexec_code.py[0m:[94m128[0m in [92mexec_func_with_error_handling[0m                            [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/streamlit/runtime/scrip[0m [31m [0m
[31m [0m [2;33mtrunner/[0m[1;33mscript_runner.py[0m:[94m669[0m in [92mcode_to_exec[0m                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mhome.py[0m:[94m229[0m in [92m<module>[0m     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m226 [0m[2m│   [0m[2m# Generate response[0m                                                        [31m [0m
[31m [0m   [2m227 [0m[2m│   [0m[94mif[0m with_files:                                                             [31m [0m
[31m [0m   [2m228 [0m[2m│   │   [0mresponse = local_gemma3n_image(message_content, max_tokens)            [31m [0m
[31m [0m [31m❱ [0m229 [2m│   [0m[94melse[0m:                                                                      [31m [0m
[31m [0m   [2m230 [0m[2m│   │   [0mresponse = st.session_state[[33m"[0m[33mopenai_client[0m[33m"[0m].chat.completions.create(  [31m [0m
[31m [0m   [2m231 [0m[2m│   │   │   [0mmodel=model_id,                                                    [31m [0m
[31m [0m   [2m232 [0m[2m│   │   │   [0mmessages=st.session_state.messages_no_files,                       [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/src/first-aid/demo/kaggle-gemma-3n-challenge/[0m[1;33mutility.py[0m:[94m68[0m in            [31m [0m
[31m [0m [92mlocal_gemma3n_image[0m                                                                  [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m65 [0m[2m│   │   [0mbase_url=openai_api_base,                                               [31m [0m
[31m [0m   [2m66 [0m[2m│   [0m)                                                                           [31m [0m
[31m [0m   [2m67 [0m[2m│   [0m                                                                            [31m [0m
[31m [0m [31m❱ [0m68 [2m│   [0mchat_response = client.chat.completions.create(                             [31m [0m
[31m [0m   [2m69 [0m[2m│   │   [0mmodel=model_id,                                                         [31m [0m
[31m [0m   [2m70 [0m[2m│   │   [0mmessages=[                                                              [31m [0m
[31m [0m   [2m71 [0m[2m│   │   │   [0m{[33m"[0m[33mrole[0m[33m"[0m: [33m"[0m[33msystem[0m[33m"[0m, [33m"[0m[33mcontent[0m[33m"[0m: [33m"[0m[33mYou are a helpful assistant. Please [0m [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/_utils/[0m[1;33m_utils.py[0m [31m [0m
[31m [0m :[94m274[0m in [92mwrapper[0m                                                                      [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m271 [0m[2m│   │   │   │   │   [0m[94melse[0m:                                                      [31m [0m
[31m [0m   [2m272 [0m[2m│   │   │   │   │   │   [0mmsg = [33mf[0m[33m"[0m[33mMissing required argument: [0m[33m{[0mquote(missing[[94m0[0m])[33m}[0m [31m [0m
[31m [0m   [2m273 [0m[2m│   │   │   │   [0m[94mraise[0m [96mTypeError[0m(msg)                                           [31m [0m
[31m [0m [31m❱ [0m274 [2m│   │   │   [0m[94mreturn[0m [1;4mfunc(*args, **kwargs)[0m                                       [31m [0m
[31m [0m   [2m275 [0m[2m│   │   [0m                                                                       [31m [0m
[31m [0m   [2m276 [0m[2m│   │   [0m[94mreturn[0m wrapper  [2m# type: ignore[0m                                         [31m [0m
[31m [0m   [2m277 [0m                                                                               [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/resources/chat/[0m[1;33mc[0m [31m [0m
[31m [0m [1;33mompletions.py[0m:[94m815[0m in [92mcreate[0m                                                          [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 812 [0m[2m│   │   [0mtimeout: [96mfloat[0m | httpx.Timeout | [94mNone[0m | NotGiven = NOT_GIVEN,         [31m [0m
[31m [0m   [2m 813 [0m[2m│   [0m) -> ChatCompletion | Stream[ChatCompletionChunk]:                        [31m [0m
[31m [0m   [2m 814 [0m[2m│   │   [0mvalidate_response_format(response_format)                             [31m [0m
[31m [0m [31m❱ [0m 815 [2m│   │   [0m[94mreturn[0m [96mself[0m._post(                                                    [31m [0m
[31m [0m   [2m 816 [0m[2m│   │   │   [0m[33m"[0m[33m/chat/completions[0m[33m"[0m,                                              [31m [0m
[31m [0m   [2m 817 [0m[2m│   │   │   [0mbody=maybe_transform(                                             [31m [0m
[31m [0m   [2m 818 [0m[2m│   │   │   │   [0m{                                                             [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1277[0m in [92mpost[0m                                                                         [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1274 [0m[2m│   │   [0mopts = FinalRequestOptions.construct(                                 [31m [0m
[31m [0m   [2m1275 [0m[2m│   │   │   [0mmethod=[33m"[0m[33mpost[0m[33m"[0m, url=path, json_data=body, files=to_httpx_files(fil [31m [0m
[31m [0m   [2m1276 [0m[2m│   │   [0m)                                                                     [31m [0m
[31m [0m [31m❱ [0m1277 [2m│   │   [0m[94mreturn[0m cast(ResponseT, [1;4;96mself[0m[1;4m.request(cast_to, opts, stream=stream, str[0m [31m [0m
[31m [0m   [2m1278 [0m[2m│   [0m                                                                          [31m [0m
[31m [0m   [2m1279 [0m[2m│   [0m[94mdef[0m [92mpatch[0m(                                                                [31m [0m
[31m [0m   [2m1280 [0m[2m│   │   [0m[96mself[0m,                                                                 [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m954[0m in [92mrequest[0m                                                                       [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m 951 [0m[2m│   │   [0m[94melse[0m:                                                                 [31m [0m
[31m [0m   [2m 952 [0m[2m│   │   │   [0mretries_taken = [94m0[0m                                                 [31m [0m
[31m [0m   [2m 953 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m [31m❱ [0m 954 [2m│   │   [0m[94mreturn[0m [96mself[0m._request(                                                 [31m [0m
[31m [0m   [2m 955 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m [0m   [2m 956 [0m[2m│   │   │   [0moptions=options,                                                  [31m [0m
[31m [0m   [2m 957 [0m[2m│   │   │   [0mstream=stream,                                                    [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m [2;33m/home/aaron/.conda/envs/dev3-11/lib/python3.11/site-packages/openai/[0m[1;33m_base_client.py[0m: [31m [0m
[31m [0m [94m1058[0m in [92m_request[0m                                                                     [31m [0m
[31m [0m                                                                                      [31m [0m
[31m [0m   [2m1055 [0m[2m│   │   │   │   [0merr.response.read()                                           [31m [0m
[31m [0m   [2m1056 [0m[2m│   │   │   [0m                                                                  [31m [0m
[31m [0m   [2m1057 [0m[2m│   │   │   [0mlog.debug([33m"[0m[33mRe-raising status error[0m[33m"[0m)                              [31m [0m
[31m [0m [31m❱ [0m1058 [2m│   │   │   [0m[1;4;94mraise[0m[1;4m [0m[1;4;96mself[0m[1;4m._make_status_error_from_response(err.response) [0m[1;4;94mfrom[0m[1;4m [0m[1;4;94mNo[0m [31m [0m
[31m [0m   [2m1059 [0m[2m│   │   [0m                                                                      [31m [0m
[31m [0m   [2m1060 [0m[2m│   │   [0m[94mreturn[0m [96mself[0m._process_response(                                        [31m [0m
[31m [0m   [2m1061 [0m[2m│   │   │   [0mcast_to=cast_to,                                                  [31m [0m
[31m────────────────────────────────────────────────────────────────────────────────────────[0m
[1;91mNotFoundError: [0mError code: [1;36m404[0m - [1m{[0m[32m'detail'[0m: [32m'Not Found'[0m[1m}[0m
